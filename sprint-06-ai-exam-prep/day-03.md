# Sprint 6 Â· Day 3

## ðŸ”’ Domains 4 & 5 â€” Responsible AI + Security & Compliance

`90 min` Â· `28% of exam combined` Â· `The "do it right" day`

---

&nbsp;

## Today's Big Picture

> Building AI that works is one thing. Building AI that's FAIR, SAFE, and LEGAL
> is another. These two domains are 28% of the exam combined.
> They're also the easiest to score on â€” the answers are common sense with AWS names attached.

By the end of today, you'll have:

- âœ… Understand responsible AI principles (bias, fairness, transparency)
- âœ… Know AWS tools for detecting and monitoring bias
- âœ… Understand AI security (data privacy, encryption, access control)
- âœ… Know governance frameworks and compliance standards
- âœ… Written a responsible AI cheatsheet

&nbsp;

---

&nbsp;

## Part 1 â€” Domain 4: Responsible AI (14%) `35 min`

&nbsp;

### The pillars of responsible AI

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RESPONSIBLE AI PRINCIPLES                           â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ FAIRNESS â”‚  â”‚ TRANS-   â”‚  â”‚ SAFETY   â”‚           â”‚
â”‚  â”‚          â”‚  â”‚ PARENCY  â”‚  â”‚          â”‚           â”‚
â”‚  â”‚ No bias  â”‚  â”‚ Explain  â”‚  â”‚ No harm  â”‚           â”‚
â”‚  â”‚ Inclusive â”‚  â”‚ how it   â”‚  â”‚ Robust   â”‚           â”‚
â”‚  â”‚ Equal    â”‚  â”‚ works    â”‚  â”‚ Tested   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ VERACITY â”‚  â”‚ PRIVACY  â”‚  â”‚ INCLUS-  â”‚           â”‚
â”‚  â”‚          â”‚  â”‚          â”‚  â”‚ IVITY    â”‚           â”‚
â”‚  â”‚ Truthful â”‚  â”‚ Protect  â”‚  â”‚ Works    â”‚           â”‚
â”‚  â”‚ Accurate â”‚  â”‚ personal â”‚  â”‚ for      â”‚           â”‚
â”‚  â”‚ Grounded â”‚  â”‚ data     â”‚  â”‚ everyone â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

&nbsp;

### Bias in AI â€” what the exam tests

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WHERE BIAS ENTERS THE PIPELINE                      â”‚
â”‚                                                      â”‚
â”‚  Data Collection â”€â”€â–¶ Training â”€â”€â–¶ Output             â”‚
â”‚       â–²                 â–²           â–²                â”‚
â”‚       â”‚                 â”‚           â”‚                â”‚
â”‚  Selection          Algorithmic  Confirmation        â”‚
â”‚  bias               bias         bias                â”‚
â”‚                                                      â”‚
â”‚  "Data doesn't    "Model          "Users only see    â”‚
â”‚   represent        amplifies       results that      â”‚
â”‚   everyone"        existing        confirm their     â”‚
â”‚                    patterns"       beliefs"           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Bias type | What it means | Example |
|-----------|--------------|---------|
| **Selection bias** | Training data doesn't represent the real population | Hiring model trained only on male resumes |
| **Measurement bias** | Data collection method is flawed | Survey only reaches tech-savvy users |
| **Algorithmic bias** | Model amplifies existing patterns in data | Loan approval model that discriminates |
| **Confirmation bias** | System reinforces existing beliefs | Search results that create echo chambers |

&nbsp;

### AWS tools for responsible AI

| Tool | What it does |
|------|-------------|
| **SageMaker Clarify** | Detect bias in data AND model predictions |
| **SageMaker Model Monitor** | Continuous monitoring for drift and bias in production |
| **SageMaker Model Cards** | Document model details: purpose, training, performance, limitations |
| **Bedrock Guardrails** | Filter harmful content, block PII, enforce topic boundaries |
| **Amazon A2I** | Human-in-the-loop â€” humans review low-confidence predictions |

&nbsp;

### Transparent vs opaque models

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                      â”‚
â”‚  TRANSPARENT / EXPLAINABLE    OPAQUE / BLACK-BOX    â”‚
â”‚                                                      â”‚
â”‚  â€¢ Decision trees             â€¢ Deep neural networks â”‚
â”‚  â€¢ Linear regression          â€¢ LLMs                 â”‚
â”‚  â€¢ Rule-based systems         â€¢ Complex ensembles    â”‚
â”‚                                                      â”‚
â”‚  Easy to explain              Hard to explain        â”‚
â”‚  WHY it decided               but often more         â”‚
â”‚  something                    accurate               â”‚
â”‚                                                      â”‚
â”‚  Trade-off: explainability â—€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ performance    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> **Exam tip:** SageMaker Model Cards help identify which models are explainable. Human-centered design for AI means keeping humans informed and in control.

&nbsp;

### Legal risks of generative AI

| Risk | What it means |
|------|--------------|
| **IP infringement** | Model generates content too similar to copyrighted work |
| **Hallucinations** | Model states false information as fact |
| **Biased outputs** | Model produces discriminatory content |
| **Loss of customer trust** | Users stop trusting the product |
| **Privacy violations** | Model reveals personal information from training data |

&nbsp;

---

&nbsp;

## Part 2 â€” Domain 5: Security, Compliance & Governance (14%) `35 min`

&nbsp;

### Securing AI systems

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AI SECURITY LAYERS                                  â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  DATA SECURITY                                 â”‚  â”‚
â”‚  â”‚  â€¢ Encryption at rest (S3, KMS)                â”‚  â”‚
â”‚  â”‚  â€¢ Encryption in transit (TLS/SSL)             â”‚  â”‚
â”‚  â”‚  â€¢ Data access control (IAM)                   â”‚  â”‚
â”‚  â”‚  â€¢ PII detection (Amazon Macie)                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  MODEL SECURITY                                â”‚  â”‚
â”‚  â”‚  â€¢ Access control to models (IAM roles)        â”‚  â”‚
â”‚  â”‚  â€¢ Prompt injection prevention (Guardrails)    â”‚  â”‚
â”‚  â”‚  â€¢ Private endpoints (VPC, PrivateLink)        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  INFRASTRUCTURE SECURITY                       â”‚  â”‚
â”‚  â”‚  â€¢ Threat detection (Amazon Inspector)         â”‚  â”‚
â”‚  â”‚  â€¢ Activity logging (CloudTrail)               â”‚  â”‚
â”‚  â”‚  â€¢ Configuration compliance (AWS Config)       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

&nbsp;

### AWS security services for AI â€” the exam cheat table

| Service | What it does | AI context |
|---------|-------------|-----------|
| **IAM** | Access control â€” who can do what | Control who can invoke models, access data |
| **AWS KMS** | Key management â€” encryption keys | Encrypt model data and training data |
| **Amazon Macie** | Detect PII in S3 | Find personal data before it enters training |
| **AWS PrivateLink** | Private network connections | Call Bedrock without going through public internet |
| **CloudTrail** | Activity logging | Track who invoked which model, when |
| **AWS Config** | Configuration compliance | Ensure AI resources follow rules |
| **Amazon Inspector** | Vulnerability scanning | Scan containers running models |
| **AWS Artifact** | Compliance reports | Access AWS compliance certifications |
| **AWS Audit Manager** | Audit automation | Generate audit reports for AI systems |
| **Secrets Manager** | Store API keys safely | Store model API keys, database passwords |

&nbsp;

### AWS Shared Responsibility Model for AI

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                      â”‚
â”‚  AWS is responsible for:                             â”‚
â”‚  â€¢ Physical infrastructure security                  â”‚
â”‚  â€¢ Network infrastructure                            â”‚
â”‚  â€¢ Bedrock/SageMaker platform security              â”‚
â”‚                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚                                                      â”‚
â”‚  YOU are responsible for:                            â”‚
â”‚  â€¢ Data security (encryption, access control)        â”‚
â”‚  â€¢ Model input/output filtering (Guardrails)        â”‚
â”‚  â€¢ Identity management (IAM policies)                â”‚
â”‚  â€¢ Compliance with regulations                       â”‚
â”‚  â€¢ Responsible AI practices                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

&nbsp;

### Data governance the exam tests

| Concept | What it means |
|---------|--------------|
| **Data lineage** | Tracking where data came from and how it was transformed |
| **Data cataloging** | Organizing and documenting datasets |
| **Data lifecycle** | Collection â†’ storage â†’ use â†’ archival â†’ deletion |
| **Data retention** | How long to keep data and when to delete it |
| **Source citation** | Documenting data origins (SageMaker Model Cards) |

&nbsp;

### Compliance standards

| Standard | What it is |
|----------|-----------|
| **ISO 27001** | Information security management |
| **SOC 1/2/3** | Service organization controls â€” security audits |
| **GDPR** | EU data protection regulation |
| **HIPAA** | US healthcare data protection |

> **Exam tip:** You don't need to know the details of each standard. Know that AWS Config, AWS Audit Manager, and AWS Artifact help with compliance.

&nbsp;

---

&nbsp;

## Part 3 â€” Write Your Cheatsheet `15 min`

Create `cheatsheets/responsible-ai-security.md`:

```markdown
# Responsible AI & Security Cheatsheet

## Responsible AI Principles
- (list the 6 pillars in your own words)

## Types of Bias
| Bias | What it means |
|------|-------------|
| (fill in) | |

## AWS Tools for Responsible AI
| Tool | What it does |
|------|-------------|
| SageMaker Clarify | |
| SageMaker Model Monitor | |
| SageMaker Model Cards | |
| Bedrock Guardrails | |
| Amazon A2I | |

## Security Services for AI
| Service | What it does |
|---------|-------------|
| (fill in) | |

## Shared Responsibility
- AWS manages: ...
- You manage: ...
```

&nbsp;

---

&nbsp;

## Part 4 â€” Commit `5 min`

```bash
git add sprint-06-ai-exam-prep/ cheatsheets/
git commit -m "sprint 6 day 3: responsible AI, bias detection, security, compliance, governance"
git push
```

&nbsp;

---

&nbsp;

## âœ… Day 3 Checklist

| | Task |
|---|------|
| â˜ | Can name the 6 responsible AI principles |
| â˜ | Know 4 types of bias and where they enter the pipeline |
| â˜ | Can name AWS tools for bias detection (Clarify, Model Monitor) |
| â˜ | Understand transparent vs opaque models |
| â˜ | Know 8+ AWS security services and their AI use cases |
| â˜ | Understand the shared responsibility model for AI |
| â˜ | Know data governance concepts (lineage, lifecycle, cataloging) |
| â˜ | Cheatsheet written and pushed ðŸŸ© |

&nbsp;

---

&nbsp;

## ðŸ§  Concepts You Now Own

| Concept | One-liner |
|---------|-----------|
| **SageMaker Clarify** | Detect bias in data and model predictions |
| **SageMaker Model Monitor** | Watch for drift and bias in production |
| **SageMaker Model Cards** | Document what a model does and how it was trained |
| **Bedrock Guardrails** | Filter harmful content, PII, off-topic responses |
| **Amazon Macie** | Find PII in S3 buckets |
| **Data lineage** | Track where data came from and how it changed |
| **Shared responsibility** | AWS secures infra, YOU secure data and access |
| **Selection bias** | Training data doesn't represent everyone |
| **Explainable AI** | Can you explain WHY the model decided something? |

&nbsp;

---

&nbsp;

> *Next: Mock Exam #1 â€” all 5 domains, just like the real thing. ðŸ’ª*
