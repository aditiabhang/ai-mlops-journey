# Sprint 6 Â· Day 1

## ðŸ—ï¸ Domain 3 â€” Applications of Foundation Models (Part 1)

`90 min` Â· `AIF-C01 highest-weight domain (28%)` Â· `The "how to use models" day`

---

&nbsp;

## Today's Big Picture

> Domain 3 is the biggest chunk of the exam. It's not about what models ARE â€”
> you already know that from Sprint 5. It's about how to USE them.
> RAG, prompt engineering risks, inference parameters, and choosing the right model.

By the end of today, you'll have:

- âœ… Deep understanding of RAG architecture
- âœ… Know how to choose a pre-trained model (selection criteria)
- âœ… Understand inference parameters and their effects
- âœ… Know prompt engineering risks (jailbreaking, poisoning, hijacking)
- âœ… Built a RAG vs Fine-tuning decision tree

&nbsp;

---

&nbsp;

## Part 1 â€” RAG Deep Dive `25 min`

&nbsp;

### What is RAG? (30-second version)

Retrieval Augmented Generation = look up relevant information FIRST, then ask the model to answer using that information. It grounds the model in YOUR data so it doesn't hallucinate.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG ARCHITECTURE                                         â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚  â”‚ Your     â”‚   1. Chunk documents                        â”‚
â”‚  â”‚ Documentsâ”‚â”€â”€â”€â”€â”€â”€â–¶ 2. Generate embeddings               â”‚
â”‚  â”‚ (S3)     â”‚            â–¼                                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   3. Store in vector DB                     â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                   â”‚  Vector Databaseâ”‚                     â”‚
â”‚                   â”‚  (OpenSearch,   â”‚                     â”‚
â”‚                   â”‚   Aurora, etc.) â”‚                     â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                            â”‚                              â”‚
â”‚  User asks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚ 4. Search for similar        â”‚
â”‚  a question                â”‚    chunks (semantic search)  â”‚
â”‚                            â–¼                              â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                   â”‚  Relevant       â”‚                     â”‚
â”‚                   â”‚  chunks found   â”‚                     â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                            â”‚                              â”‚
â”‚                            â–¼ 5. Send question +           â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    relevant docs    â”‚
â”‚                   â”‚  Foundation     â”‚    to model          â”‚
â”‚                   â”‚  Model          â”‚                     â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                            â”‚                              â”‚
â”‚                            â–¼ 6. Model answers using       â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    YOUR data        â”‚
â”‚                   â”‚  Grounded       â”‚                     â”‚
â”‚                   â”‚  Response âœ…    â”‚                     â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

&nbsp;

### Why RAG? Why not just fine-tune?

| | RAG | Fine-tuning |
|--|-----|-------------|
| **What it does** | Retrieves external data at query time | Changes model weights with new training data |
| **Data freshness** | Always current â€” update docs anytime | Frozen at training time |
| **Cost** | Cheaper â€” no retraining | Expensive â€” GPU hours for training |
| **Setup time** | Hours | Days to weeks |
| **When to use** | Q&A over docs, support bots, search | Domain-specific language, specialized tasks |
| **Hallucination risk** | Lower â€” grounded in real docs | Lower for its domain, but still possible |

&nbsp;

### AWS services for RAG

| Component | AWS Service |
|-----------|------------|
| **Document storage** | Amazon S3 |
| **Embedding generation** | Amazon Bedrock (Titan Embeddings) |
| **Vector database** | Amazon OpenSearch, Amazon Aurora, Amazon Neptune, Amazon DocumentDB, Amazon RDS for PostgreSQL |
| **Orchestration** | Bedrock Knowledge Bases (does it all for you) |

> **Exam tip:** If a question says "the company wants to answer questions using their internal documents" â€” the answer is almost always **RAG with Bedrock Knowledge Bases**.

&nbsp;

---

&nbsp;

## Part 2 â€” Choosing a Model `15 min`

&nbsp;

### Model selection criteria the exam tests

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HOW TO CHOOSE A FOUNDATION MODEL                    â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  COST    â”‚  â”‚  LATENCY â”‚  â”‚ ACCURACY â”‚           â”‚
â”‚  â”‚          â”‚  â”‚          â”‚  â”‚          â”‚           â”‚
â”‚  â”‚ Bigger = â”‚  â”‚ Bigger = â”‚  â”‚ Bigger = â”‚           â”‚
â”‚  â”‚ more $$  â”‚  â”‚ slower   â”‚  â”‚ better   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ MODALITY â”‚  â”‚ LANGUAGE â”‚  â”‚ CONTEXT  â”‚           â”‚
â”‚  â”‚          â”‚  â”‚          â”‚  â”‚ WINDOW   â”‚           â”‚
â”‚  â”‚ Text?    â”‚  â”‚ Multi-   â”‚  â”‚          â”‚           â”‚
â”‚  â”‚ Image?   â”‚  â”‚ lingual? â”‚  â”‚ How much â”‚           â”‚
â”‚  â”‚ Code?    â”‚  â”‚          â”‚  â”‚ can it   â”‚           â”‚
â”‚  â”‚ Multi?   â”‚  â”‚          â”‚  â”‚ "see"?   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                      â”‚
â”‚  Also consider: compliance, customization needs,     â”‚
â”‚  model complexity, input/output length limits        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

&nbsp;

### Quick decision pattern

| Need | Model choice |
|------|-------------|
| Cheapest option | Smaller model (Titan Lite, Llama 8B) |
| Fastest response | Smaller model + provisioned throughput |
| Best quality | Largest available model (Claude, GPT-4) |
| Multi-language | Models with multilingual training |
| Image + text | Multimodal model (Titan, Gemini) |
| Maximum context | Claude (200K), GPT-4 (128K) |
| Open source / on-prem | Llama, Mistral |

&nbsp;

---

&nbsp;

## Part 3 â€” Inference Parameters `15 min`

&nbsp;

### The parameters and their effects

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INFERENCE PARAMETERS                                â”‚
â”‚                                                      â”‚
â”‚  Temperature â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚  0.0          0.3          0.7          1.0           â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
â”‚  Deterministic  Focused     Balanced     Creative    â”‚
â”‚  Factual        Best for    General      Wild        â”‚
â”‚  Repetitive     support     purpose      Varied      â”‚
â”‚                                                      â”‚
â”‚  Top-p â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚  0.1           0.5           0.9           1.0       â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”‚
â”‚  Very narrow    Moderate      Broad         All      â”‚
â”‚  Safe answers   selection     diverse      tokens    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Parameter | What it controls | Low value | High value |
|-----------|-----------------|-----------|------------|
| **Temperature** | Randomness of output | Consistent, factual | Creative, varied |
| **Top-p** | Token selection pool | Fewer choices, safer | More choices, diverse |
| **Top-k** | Number of tokens to consider | Conservative | Exploratory |
| **Max tokens** | Response length limit | Short answer | Long answer |
| **Stop sequences** | When to stop generating | Cuts off at trigger | â€” |

&nbsp;

### Exam scenario patterns

| Scenario | Recommended settings |
|----------|---------------------|
| Customer support chatbot | Low temperature (0.1-0.3), moderate max tokens |
| Creative story writing | High temperature (0.7-0.9), high max tokens |
| Code generation | Low temperature (0.1-0.2), precise |
| Data extraction | Temperature 0, deterministic output |
| Summarization | Low temperature (0.2-0.3), controlled length |

&nbsp;

---

&nbsp;

## Part 4 â€” Prompt Engineering Risks `15 min`

&nbsp;

### The risks the exam tests

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PROMPT ENGINEERING RISKS                            â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ JAILBREAK  â”‚  â”‚ PROMPT     â”‚  â”‚ PROMPT     â”‚     â”‚
â”‚  â”‚            â”‚  â”‚ INJECTION  â”‚  â”‚ LEAKING    â”‚     â”‚
â”‚  â”‚ Trick the  â”‚  â”‚            â”‚  â”‚            â”‚     â”‚
â”‚  â”‚ model into â”‚  â”‚ Hidden     â”‚  â”‚ Model      â”‚     â”‚
â”‚  â”‚ ignoring   â”‚  â”‚ instructionsâ”‚ â”‚ reveals    â”‚     â”‚
â”‚  â”‚ its rules  â”‚  â”‚ in user    â”‚  â”‚ its system â”‚     â”‚
â”‚  â”‚            â”‚  â”‚ input      â”‚  â”‚ prompt     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ DATA       â”‚  â”‚ MODEL      â”‚                      â”‚
â”‚  â”‚ POISONING  â”‚  â”‚ HIJACKING  â”‚                      â”‚
â”‚  â”‚            â”‚  â”‚            â”‚                      â”‚
â”‚  â”‚ Bad data   â”‚  â”‚ Redirect   â”‚                      â”‚
â”‚  â”‚ in trainingâ”‚  â”‚ model to   â”‚                      â”‚
â”‚  â”‚ corrupts   â”‚  â”‚ do attackerâ”‚                      â”‚
â”‚  â”‚ the model  â”‚  â”‚ 's task    â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Risk | What it is | Mitigation |
|------|-----------|------------|
| **Jailbreaking** | User tricks model into bypassing safety rules | Guardrails, input filtering |
| **Prompt injection** | Malicious instructions hidden in user input | Input validation, Bedrock Guardrails |
| **Prompt leaking** | Model reveals its system prompt to the user | Don't put secrets in system prompts |
| **Data poisoning** | Training data is corrupted intentionally | Data validation, curation |
| **Model hijacking** | Redirecting model to serve attacker's goals | Access controls, monitoring |

> **Exam tip:** "How to prevent prompt injection?" â†’ **Bedrock Guardrails** + input validation.

&nbsp;

---

&nbsp;

## Part 5 â€” Build the Decision Tree `15 min`

Create `cheatsheets/rag-vs-finetuning.md`:

```markdown
# RAG vs Fine-tuning vs Prompt Engineering â€” Decision Tree

## When to use what?

```
Need to answer questions from your docs?
  â””â”€ YES â†’ RAG (Bedrock Knowledge Bases)

Need the model to speak a specialized language?
  â””â”€ YES â†’ Fine-tuning

Need better answers without changing the model?
  â””â”€ YES â†’ Prompt engineering (few-shot, CoT)

Need real-time data access?
  â””â”€ YES â†’ RAG (always up-to-date)

Budget is tight?
  â””â”€ YES â†’ Prompt engineering (free) â†’ RAG (cheap) â†’ Fine-tuning (expensive)
```

## Cost comparison

| Method | Cost | Setup Time | Data Freshness |
|--------|------|------------|---------------|
| Prompt engineering | Free | Minutes | N/A |
| RAG | $ | Hours | Always current |
| Fine-tuning | $$$ | Days | Frozen at training |
| Pre-training | $$$$$ | Weeks | Frozen |
```

&nbsp;

---

&nbsp;

## Part 6 â€” Commit `5 min`

```bash
git add sprint-06-ai-exam-prep/ cheatsheets/
git commit -m "sprint 6 day 1: domain 3 â€” RAG, model selection, inference params, prompt risks"
git push
```

&nbsp;

---

&nbsp;

## âœ… Day 1 Checklist

| | Task |
|---|------|
| â˜ | Can draw the RAG architecture from memory |
| â˜ | Know when to use RAG vs fine-tuning vs prompt engineering |
| â˜ | Can name AWS services for each RAG component |
| â˜ | Understand model selection criteria |
| â˜ | Know all inference parameters and their effects |
| â˜ | Can name 5 prompt engineering risks and their mitigations |
| â˜ | Decision tree cheatsheet written and pushed ðŸŸ© |

&nbsp;

---

&nbsp;

## ðŸ§  Concepts You Now Own

| Concept | One-liner |
|---------|-----------|
| **RAG** | Retrieve docs first, then ask the model â€” grounded answers |
| **Vector database** | Stores embeddings for semantic search |
| **Bedrock Knowledge Bases** | Managed RAG â€” upload docs, done |
| **Fine-tuning** | Retrain model weights on your data â€” expensive, frozen |
| **Temperature** | Randomness dial â€” low = focused, high = creative |
| **Top-p** | Token selection pool size |
| **Jailbreaking** | Tricking model into ignoring safety rules |
| **Prompt injection** | Hidden malicious instructions in user input |
| **Data poisoning** | Corrupting training data intentionally |
| **Guardrails** | Bedrock feature to filter harmful content |

&nbsp;

---

&nbsp;

> *Next: Fine-tuning process, model evaluation metrics, and a model serving project. ðŸ”¬*
